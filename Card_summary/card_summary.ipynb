{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pdfplumber\n",
    "import pandasql as psql\n",
    "import re\n",
    "from prettytable import PrettyTable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_texto_pdf(ruta_pdf):\n",
    "    texto_completo = \"\"\n",
    "    \n",
    "    with pdfplumber.open(ruta_pdf) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            texto_completo += page.extract_text()\n",
    "    \n",
    "    return texto_completo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encolumnar_datos(texto):\n",
    "    \"\"\"\n",
    "    Esta función recibe una cadena de texto con datos en formato no estructurado y los convierte en columnas.\n",
    "    \n",
    "    :param texto: Cadena de texto con datos no estructurados.\n",
    "    :return: DataFrame de pandas con los datos encolumnados.\n",
    "    \"\"\"\n",
    "    # Separar cada línea del texto\n",
    "    lineas = texto.strip().split('\\n')\n",
    "    \n",
    "    # Crear una lista para almacenar las filas procesadas\n",
    "    filas = []\n",
    "    \n",
    "    # Procesar cada línea para separar en columnas\n",
    "    for linea in lineas:\n",
    "        # Usar una expresión regular para capturar las columnas, con la columna Cuotas opcional\n",
    "        patron = r'(\\d{2}-\\d{2}-\\d{2})\\s+([*K]?\\s?[A-Z].+?)(?:\\s+(\\d{2}/\\d{2}))?\\s+(\\d{6})\\s+([\\d.,]+)'\n",
    "        coincidencia = re.match(patron, linea)\n",
    "        \n",
    "        if coincidencia:\n",
    "            fecha, descripcion, cuotas, comprobante, monto = coincidencia.groups()\n",
    "            # Si no hay información en Cuotas, dejar el campo vacío\n",
    "            cuotas = cuotas if cuotas else ''\n",
    "            filas.append([fecha, descripcion.strip(), cuotas, comprobante, monto])\n",
    "    \n",
    "    # Crear un DataFrame con las filas procesadas\n",
    "    df = pd.DataFrame(filas, columns=['Fecha', 'Descripcion', 'Cuotas', 'Comprobante', 'Monto'])\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_df():\n",
    "    summary_list =['resumen_enero.pdf','resumen_febrero.pdf','resumen_marzo.pdf','resumen_abril.pdf','resumen_mayo.pdf','resumen_junio.pdf','resumen_julio.pdf','resumen_agosto.pdf','resumen_septiembre.pdf','resumen_octubre.pdf','resumen_noviembre.pdf','resumen_diciembre.pdf'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consumption_analysis(df):\n",
    "\n",
    "    # Funcion para identificar cantidad de consumos en un mismo local:\n",
    "    \n",
    "    # Contar la frecuencia de cada valor en la columna 'Descripción'\n",
    "    conteo = df['Descripcion'].value_counts()\n",
    "    \n",
    "    # Mapear el conteo de frecuencias a la columna del DataFrame\n",
    "    df['q_repetido'] = df['Descripcion'].map(conteo)\n",
    "    \n",
    "    #------------------------------------------------------------------------------------\n",
    "    # Funcion para identificar consumos duplicados:\n",
    "    \n",
    "    df['concat_desc_monto'] = df['Fecha'] + '' + df['Descripcion'] + ' ' + df['Monto']\n",
    "    \n",
    "    # Contar la frecuencia de cada valor en la columna 'Descripción'\n",
    "    conteo_consum_dupli = df['concat_desc_monto'].value_counts()\n",
    "    \n",
    "    # Mapear el conteo de frecuencias a la columna del DataFrame\n",
    "    df['consumo_duplicado'] = df['concat_desc_monto'].map(conteo_consum_dupli) \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construccion de categorias:\n",
    "\n",
    "def apply_categories (df):\n",
    "\n",
    "    categorias = {\n",
    "        '* TIENDA DE CAFE': 'salida',\n",
    "        '* RAPPI ARG S.A.S.': 'comida',\n",
    "        '* MOLINA PANADERIA': 'salida',\n",
    "        '* DIA TIENDA 409': 'comida',\n",
    "        '* FARMACITY': 'medicina',\n",
    "        'P MICROSOFT*1 MES Z62PJZACGU5Q115776': 'suscripcion',\n",
    "        '* MEDICUS SA DEB A 12688472000': 'obra social',\n",
    "        '* RES BOYACA': 'comida',\n",
    "        'V LinkedIn Pre P38 LinkedIn Pre P3821': 'suscripcion',\n",
    "        '* CARREFOUR EXPRESS AV CARA': 'comida',\n",
    "        '* PERSONAL FLOW 100329902571001': 'servicios',\n",
    "        'K HAVANNA SA': 'salidas',\n",
    "        '* ALMACEN DE PIZZAS': 'salidas',\n",
    "        '* EDESUR DEB AUT 056340211': 'servicios',\n",
    "        '* MULTIPASTA': 'comida',\n",
    "        '* RAPPI': 'comida',\n",
    "        'K MERPAGO*SPORTCLU': 'gimansio',\n",
    "        'P MICROSOFT*1 MES Z62FLR7HJIKF115776': 'suscripcion',\n",
    "        '* LA TROPILLA CARNICERIA ': 'comida',\n",
    "        '* CAFE REGISTRADO': 'salida',\n",
    "        '* OTAWA DELI S.A.': 'comida',\n",
    "        '* DLO*RAPPI.': 'comida',\n",
    "        '* RUIZ LA PASTELERIA': 'comida',\n",
    "        '* FOGOSA': 'salida',\n",
    "        '* LA BUENOS AIRES PASTEL': 'comida',\n",
    "        '* EASY CABALLITO': 'hogar',\n",
    "        '* QUOTIDIANO-QUOTIDIANO': 'salida',\n",
    "        '* KUKE SRL - AXION': 'auto',\n",
    "        'K MERPAGO*PSA': 'hogar',\n",
    "        '* SARKANYSOFIA ALCORTA': 'hogar',\n",
    "        '* FIERA': 'salida',\n",
    "        '* NFS ARCOS': 'salida'}\n",
    "\n",
    "    df['categoria'] = df['Descripcion'].map(categorias)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visual_style(df):\n",
    "# Formato visual para la tabla de salda\n",
    "\n",
    "# Setup de opciones para la visualizacion de los DF correctamente en Visual Studio\n",
    "\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Prety Table Format:\n",
    "\n",
    "    df_new_style = PrettyTable()\n",
    "    df_new_style.field_names = df.columns.tolist()\n",
    "    for row in df.itertuples(index=False):\n",
    "         df_new_style.add_row(row)\n",
    "\n",
    "    return(df_new_style)     \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Main***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se ejecuta la funcion de lectura del PDF y traduccion a DF:\n",
    "def main(file_name):\n",
    "    texto = extraer_texto_pdf('resumen_septiembre.pdf')   # Lectura del PDF\n",
    "    df_sumary_card = (encolumnar_datos(texto))            # Transformacion del PDF en DF\n",
    "    df_sumary_card = consumption_analysis(df_sumary_card) # Construye las agregaciones necesarias para el analisis\n",
    "    df_sumary_card = apply_categories (df_sumary_card)    # Se generan las categorias que clasifican los consumos\n",
    "    df_sumary_card = visual_style(df_sumary_card)\n",
    "\n",
    "    return df_sumary_card"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Fecha                            Descripcion Cuotas Comprobante  \\\n",
      "0   23-06-24                    K MERPAGO*TCTIENDAS  03/06      222697   \n",
      "1   04-07-24                          K MERPAGO*PSA  03/06      212596   \n",
      "2   09-08-24                 K MERPAGO*MERCADOLIBRE  02/06      143241   \n",
      "3   22-08-24         * MEDICUS SA DEB A 12688472000             545063   \n",
      "4   23-08-24                     K MERPAGO*SPORTCLU             474832   \n",
      "5   23-08-24                                * RAPPI             004033   \n",
      "6   24-08-24   P MICROSOFT*1 MES Z62JNQ1XVP8B115776             074008   \n",
      "7   24-08-24                * QUOTIDIANO-QUOTIDIANO             838912   \n",
      "8   24-08-24                     * KUKE SRL - AXION             001656   \n",
      "9   24-08-24                                * FIERA             000385   \n",
      "10  25-08-24                   K MERPAGO*GOOPYSTORE             148977   \n",
      "11  26-08-24  V LinkedIn Pre P77 LinkedIn Pre P7767             857802   \n",
      "12  26-08-24                           * RES BOYACA             886116   \n",
      "13  26-08-24                           K HAVANNA SA             007413   \n",
      "14  27-08-24                   * MERPAGO*MOLINACAFE             805742   \n",
      "15  27-08-24            * CARREFOUR EXPRESS AV CARA             001269   \n",
      "16  28-08-24             * EDESUR DEB AUT 056340211             000001   \n",
      "17  29-08-24                   K MERPAGO*NORTHPHARM             536945   \n",
      "18  29-08-24                       * DIA TIENDA 409             208705   \n",
      "19  29-08-24                           K HAVANNA SA             007554   \n",
      "20  30-08-24                       * EASY CABALLITO             150417   \n",
      "21  31-08-24               * LA BUENOS AIRES PASTEL             022582   \n",
      "22  31-08-24                       * GOYENA BAR SRL             007360   \n",
      "23  02-09-24                 K MERPAGO*MERCADOLIBRE             447614   \n",
      "24  02-09-24        * PERSONAL FLOW 100329902571001             021106   \n",
      "25  03-09-24                                * RAPPI             001181   \n",
      "26  03-09-24                                * RAPPI             006189   \n",
      "27  07-09-24                   DUFRY COP 150.210,00             056654   \n",
      "28  07-09-24                 XUE CAFE COP 65.384,00             059379   \n",
      "29  02-04-24                            * NFS ARCOS  06/06      984140   \n",
      "30  11-05-24                 * SARKANYSOFIA ALCORTA  05/06      006189   \n",
      "31  21-06-24                     * FURZAI UNICENTER  03/03      923094   \n",
      "32  06-07-24                      * CAPRICHO ANIMAL  03/03      863562   \n",
      "33  29-08-24                               * ARREDO  01/03      000954   \n",
      "\n",
      "         Monto  \n",
      "0    37.539,66  \n",
      "1    47.300,00  \n",
      "2    14.950,83  \n",
      "3    46.951,71  \n",
      "4    34.000,00  \n",
      "5    18.039,50  \n",
      "6     6.999,00  \n",
      "7    19.200,00  \n",
      "8    54.005,00  \n",
      "9    39.800,00  \n",
      "10   32.659,08  \n",
      "11    1.999,00  \n",
      "12   19.981,50  \n",
      "13   17.700,00  \n",
      "14    9.100,00  \n",
      "15   42.237,00  \n",
      "16   21.487,41  \n",
      "17  116.000,00  \n",
      "18   10.090,00  \n",
      "19    5.800,00  \n",
      "20   49.619,00  \n",
      "21   10.000,00  \n",
      "22   63.200,00  \n",
      "23   34.690,00  \n",
      "24   47.874,02  \n",
      "25    3.999,00  \n",
      "26   18.359,50  \n",
      "27       36,36  \n",
      "28       15,83  \n",
      "29    7.999,66  \n",
      "30   10.616,66  \n",
      "31   38.333,33  \n",
      "32    9.996,66  \n",
      "33   25.993,34  \n"
     ]
    }
   ],
   "source": [
    "texto = extraer_texto_pdf('resumen_septiembre.pdf')   # Lectura del PDF\n",
    "df_sumary_card = (encolumnar_datos(texto))            # Transformacion del PDF en DF\n",
    "#df_sumary_card = consumption_analysis(df_sumary_card) # Construye las agregaciones necesarias para el analisis\n",
    "#df_sumary_card = apply_categories (df_sumary_card)    # Se generan las categorias que clasifican los consumos\n",
    "#df_sumary_card = visual_style(df_sumary_card)\n",
    "\n",
    "print(df_sumary_card)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
